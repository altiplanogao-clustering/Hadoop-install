---

- set_fact:
    spark_ic:
      name: spark
      install_path: '{{ spark_conf.install_dir }}'
      url: '{{ spark_res.url }}'
      file: '{{ spark_res.file }}'
      basename: '{{ spark_res.basename }}'
    spark_path: '{{ spark_conf.install_dir }}/{{ spark_res.basename}}'
# delete spark installation, configuration and data
- name: Delete spark installation - {{ spark_path }}
  file: path="{{ spark_path }}" state=absent
  when: fresh_unzip | default(true)
- name: Delete spark_res_dir - {{ spark_res_dir }}
  file: path="{{ spark_res_dir }}" state=absent
  when: fresh_unzip | default(true)

# install spark files

- name: Download {{ spark_ic.file }}
  cached_get_url:
    cached: "{{ resource_cache }}/{{ spark_ic.file }}"
    url: "{{ spark_ic.url }}"
    dest: '{{ spark_ic.install_path }}/{{ spark_ic.file }}'
- name: Unarchive package - {{ spark_ic.install_path }}
  unarchive:
    src: "{{ spark_ic.install_path }}/{{ spark_ic.file }}"
    dest: "{{ spark_ic.install_path }}"
    remote_src: yes
# - name: download and unzip
#   include_role:
#     name: basic/download_and_unzip
#   vars:
#     pkg_conf: '{{ spark_ic }}'

# export HADOOP environment variables
- name: Export SPARK_HOME ...
  blockinfile:
    path: /etc/environment
    marker: "# {mark} SPARK BLOCK"
    block: |
      SPARK_HOME={{ spark_path }}
- name: Export SPARK_HOME ...
  blockinfile:
    path: "{{ sys_profile }}"
    marker: "# {mark} SPARK BLOCK"
    block: |
      export SPARK_HOME={{ spark_path }}

#  when: ansible_os_family == "RedHat"
- name: Export SPARK_HOME to PATH
  lineinfile:
    dest: '{{ sys_profile }}'
    line: 'export PATH=$PATH:$SPARK_HOME/bin'
# - name: fetch JAVA_HOME
#   command: /bin/bash -l -c "echo $JAVA_HOME"
#   changed_when: false
#   register: fetch_java_home
# - debug: msg="JAVA_HOME={{ fetch_java_home.stdout}}"
# - name: set spark JAVA_HOME
#   lineinfile:
#     dest: "{{ spark_path }}/etc/spark/spark-env.sh"
#     regexp: '^export JAVA_HOME='
#     line: 'export JAVA_HOME={{ fetch_java_home.stdout}}'

